{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sb \n",
    "%matplotlib inline \n",
    "\n",
    "from statsmodels.tsa.ar_model import AutoReg \n",
    "from sklearn.metrics import mean_squared_error \n",
    " \n",
    "# from pandas.plotting import lag_plot, autocorrelation_plot \n",
    "# from statsmodels.tsa.seasonal import seasonal_decompose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_tmp = pd.read_csv('../Datasets/daily-min-temperatures.csv', header=0, parse_dates=[0])  \n",
    "min_tmp = pd.read_csv('../Datasets/daily-min-temperatures.csv', header=0, parse_dates=[0], index_col=0) \n",
    "min_tmp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_tmp.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isinstance(min_tmp.index, pd.DatetimeIndex):\n",
    "    min_tmp.index = pd.to_datetime(min_tmp.index)\n",
    "    print('Converted index to DateTime format.') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_tmp.index = min_tmp.index.to_period('D')      # Works with index_col=0 in read_csv \n",
    "min_tmp "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test and Train split - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = min_tmp[1: (min_tmp.shape[0]-7)], min_tmp[(min_tmp.shape[0]-7):]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y, test_y = train['Temp'], test['Temp'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" y_train size : {train_y.shape} \\n y_test size : {test_y.shape}\") \n",
    "print(f\" y_train : {train_y} \\n y_test : {test_y}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Regression Model -  \n",
    "(Regression of lagged values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = int(input(\"Number of Lags : \")) \n",
    "model = AutoReg(train['Temp'], lags=l)    \n",
    "model_fit = model.fit() \n",
    "model_fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of lag variables \n",
    "\n",
    "# kar = model_fit.k_ar \n",
    "# kar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficient of lag values \n",
    "model_fit.params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_fit.predict(start=len(train), end=(len(train) + len(test) - 1))  \n",
    "preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test = mean_squared_error(test_y, preds) \n",
    "print(f\"Mean Squared Error (Test) : {mse_test}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_y.index.to_timestamp(), test_y)  \n",
    "plt.plot(test_y.index.to_timestamp(), preds, color='red') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk-Forward Validation -  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = min_tmp.Temp[1: (min_tmp.shape[0]-7)], min_tmp.Temp[(min_tmp.shape[0]-7):]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = train     # Data variable to hold test values for future predictions \n",
    "# model = AutoReg(data, lags=l) \n",
    "\n",
    "l = int(input(\"Number of Lags : \")) \n",
    "model = AutoReg(train, lags=l) \n",
    "model_fit = model.fit() \n",
    "\n",
    "prev = list(train)     # Store past observations \n",
    "pred_y_val = [] \n",
    "\n",
    "for t in test:\n",
    "\n",
    "    y = model_fit.predict(start=len(prev), end=len(prev)) \n",
    "    print(y.values[0]) \n",
    "    \n",
    "    pred_y_val.append(y.values[0]) \n",
    "    prev.append(t)  \n",
    "\n",
    "\n",
    "# for t in test:\n",
    "#     y = model_fit.predict(start=len(train), end=(len(train) + len(test) - 1)) \n",
    "#     print(y.values[0]) \n",
    "#     pred_y_val.append(y.values[0]) \n",
    "\n",
    "#     data = np.append(data, t) \n",
    "#     data = pd.Series(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test_wf = mean_squared_error(test.values, pred_y_val) \n",
    "print(f\"Mean Squared Error (Test) : {mse_test_wf}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test.index.to_timestamp(), test.values, label=\"Actual\")\n",
    "plt.plot(test.index.to_timestamp(), pred_y_val, color='red', linestyle='dashed', label=\"Predicted\")\n",
    "plt.legend() \n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
